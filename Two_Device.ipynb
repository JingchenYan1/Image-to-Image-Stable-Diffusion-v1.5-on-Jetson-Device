{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WONmGCwRwKJf"
      },
      "outputs": [],
      "source": [
        "# Grant read and write permissions to the folder\n",
        "sudo mkdir -p /data/images/stable-diffusion/uploads\n",
        "\n",
        "sudo chown -R $USER:$USER /data/images/stable-diffusion/uploads\n",
        "\n",
        "sudo chmod -R 755 /data/images/stable-diffusion/uploads\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import psutil\n",
        "import json\n",
        "\n",
        "def get_status():\n",
        "\n",
        "    cpu = psutil.cpu_percent(interval=0.5)\n",
        "    mem = psutil.virtual_memory().percent\n",
        "    return {\"cpu\": cpu, \"mem\": mem}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    status = get_status()\n",
        "    print(json.dumps(status))\n"
      ],
      "metadata": {
        "id": "18P5UeBwwMZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code above is used to monitor the Memory and CPU usage of server\n",
        "chmod +x monitor.py"
      ],
      "metadata": {
        "id": "VFGybb0NwNq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For instructions on how to download the model and launch Docker, please refer to the example code in All on One Device.ipynb."
      ],
      "metadata": {
        "id": "9wr9-NegP1U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want the server to preload the model before the task starts, use the following code\n",
        "nano img2img_server.py"
      ],
      "metadata": {
        "id": "6YkuJAz_wO6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "img2img_server.py\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os, time, glob, json, traceback\n",
        "import torch, numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from einops import repeat\n",
        "from torch import autocast, no_grad\n",
        "from contextlib import nullcontext\n",
        "from pytorch_lightning import seed_everything\n",
        "from ldm.util import instantiate_from_config\n",
        "from ldm.models.diffusion.ddim import DDIMSampler\n",
        "\n",
        "UPLOAD_DIR         = \"/data/images/stable-diffusion/uploads\"\n",
        "INIT_IMG           = os.path.join(UPLOAD_DIR, \"init_img.png\")\n",
        "PROMPT_FILE        = os.path.join(UPLOAD_DIR, \"prompt.txt\")\n",
        "LATENT_FILE        = os.path.join(UPLOAD_DIR, \"init_latent.pt\")\n",
        "COND_FILE          = os.path.join(UPLOAD_DIR, \"encoded_condition.pt\")\n",
        "META_FILE          = os.path.join(UPLOAD_DIR, \"intermediate_meta.json\")\n",
        "DENOISED_FILE      = os.path.join(UPLOAD_DIR, \"denoised_latent.pt\")\n",
        "FLAG_RUN_DENOISE   = os.path.join(UPLOAD_DIR, \"run_denoise.flag\")\n",
        "FLAG_RUN_DECODE    = os.path.join(UPLOAD_DIR, \"run_decode.flag\")\n",
        "FLAG_ENCODE_DONE   = os.path.join(UPLOAD_DIR, \"encode_done.flag\")\n",
        "FLAG_DENOISE_DONE  = os.path.join(UPLOAD_DIR, \"denoise_done.flag\")\n",
        "\n",
        "OUT_DIR            = \"/data/images/stable-diffusion/test\"\n",
        "CONFIG_PATH        = \"/opt/stable-diffusion/configs/stable-diffusion/v1-inference.yaml\"\n",
        "CKPT_PATH          = \"/data/models/stable-diffusion/sd-v1-5.ckpt\"\n",
        "\n",
        "DEFAULT_DDIM_STEPS = 50\n",
        "DEFAULT_DDIM_ETA   = 0.0\n",
        "DEFAULT_STRENGTH   = 0.30\n",
        "DEFAULT_SCALE      = 5.0\n",
        "\n",
        "AMP_DEVICE         = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def log(m): print(m, flush=True)\n",
        "def to_uint8_img(x):\n",
        "    return (x.mul(255).add_(0.5).clamp(0,255).permute(1,2,0).detach().cpu().numpy().astype(np.uint8))\n",
        "def save_flag(path):\n",
        "    open(path, 'w').close()\n",
        "    try: os.chmod(path, 0o666)\n",
        "    except: pass\n",
        "    log(f\"[flag] {os.path.basename(path)}\")\n",
        "\n",
        "def ensure_dirs():\n",
        "    os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "    for p in [UPLOAD_DIR, OUT_DIR]:\n",
        "        try: os.chmod(p, 0o777)\n",
        "        except: pass\n",
        "\n",
        "def load_image(path, device, batch=1):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    w, h = img.size; w -= w%32; h -= h%32\n",
        "    img = img.resize((w, h), resample=Image.LANCZOS)\n",
        "    arr = np.array(img).astype(np.float32)/255.0\n",
        "    x = torch.from_numpy(arr[None].transpose(0,3,1,2)).to(device) * 2 - 1\n",
        "    return repeat(x, '1 ... -> b ...', b=batch), (w, h)\n",
        "\n",
        "def to_device(x, device):\n",
        "    if isinstance(x, torch.Tensor): return x.to(device)\n",
        "    if isinstance(x, (list,tuple)): return [to_device(t, device) for t in x]\n",
        "    if isinstance(x, dict): return {k:to_device(v, device) for k,v in x.items()}\n",
        "    return x\n",
        "\n",
        "log(\"[server] init…\")\n",
        "ensure_dirs()\n",
        "seed_everything(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cfg    = OmegaConf.load(CONFIG_PATH)\n",
        "pl_sd  = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "sd     = pl_sd.get(\"state_dict\", pl_sd)\n",
        "\n",
        "model  = instantiate_from_config(cfg.model).to(device).eval()\n",
        "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
        "sampler = DDIMSampler(model)\n",
        "sf_local = float(getattr(model, \"scale_factor\", 0.18215))\n",
        "log(f\"[server] model on {device}, scale_factor(local)={sf_local}, missing={len(missing)}, unexpected={len(unexpected)}\")\n",
        "\n",
        "def do_encode():\n",
        "    log(\"[encode] start\")\n",
        "    try:\n",
        "        x, (w,h) = load_image(INIT_IMG, device, batch=1)\n",
        "        with no_grad():\n",
        "            z = model.get_first_stage_encoding(model.encode_first_stage(x))\n",
        "        if torch.cuda.is_available(): torch.cuda.synchronize()\n",
        "        torch.save(z.cpu(), LATENT_FILE); os.chmod(LATENT_FILE, 0o666)\n",
        "\n",
        "        with open(PROMPT_FILE) as f:\n",
        "            prompt = f.read().strip()\n",
        "        with no_grad():\n",
        "            c = model.get_learned_conditioning([prompt])\n",
        "        if isinstance(c, torch.Tensor): torch.save(c.cpu(), COND_FILE)\n",
        "        elif isinstance(c, (list,tuple)): torch.save([t.cpu() if isinstance(t, torch.Tensor) else t for t in c], COND_FILE)\n",
        "        elif isinstance(c, dict): torch.save({k:(v.cpu() if isinstance(v, torch.Tensor) else v) for k,v in c.items()}, COND_FILE)\n",
        "        else: torch.save(c, COND_FILE)\n",
        "        os.chmod(COND_FILE, 0o666)\n",
        "\n",
        "        meta = {\n",
        "            \"width\": w, \"height\": h, \"n_samples\": 1,\n",
        "            \"steps\": DEFAULT_DDIM_STEPS, \"eta\": DEFAULT_DDIM_ETA,\n",
        "            \"strength\": DEFAULT_STRENGTH, \"scale\": DEFAULT_SCALE,\n",
        "            \"scale_factor\": sf_local,\n",
        "            \"ckpt\": os.path.basename(CKPT_PATH),\n",
        "            \"config\": os.path.basename(CONFIG_PATH),\n",
        "            \"seed\": 42\n",
        "        }\n",
        "        with open(META_FILE, \"w\") as f: json.dump(meta, f, indent=2)\n",
        "        os.chmod(META_FILE, 0o666)\n",
        "\n",
        "        with no_grad(): recon = model.decode_first_stage(z)\n",
        "        recon = torch.clamp((recon+1)/2, 0, 1)\n",
        "        Image.fromarray(to_uint8_img(recon[0])).save(os.path.join(OUT_DIR,\"recon_encode.png\"))\n",
        "\n",
        "        save_flag(FLAG_ENCODE_DONE)\n",
        "        log(\"[encode] done\")\n",
        "    except Exception:\n",
        "        log(\"[encode] ERROR:\"); traceback.print_exc()\n",
        "\n",
        "def do_denoise():\n",
        "    log(\"[denoise] start\")\n",
        "    try:\n",
        "        z = torch.load(LATENT_FILE, map_location=\"cpu\"); z = to_device(z, device)\n",
        "        c = torch.load(COND_FILE, map_location=\"cpu\"); c = to_device(c, device)\n",
        "        with open(META_FILE) as f: meta = json.load(f)\n",
        "\n",
        "        sf_send = float(meta.get(\"scale_factor\", sf_local))\n",
        "        if abs(sf_send - sf_local) > 1e-6:\n",
        "            scale = sf_send / sf_local\n",
        "            log(f\"[denoise] rescale latent by {scale:.6f} (send={sf_send} local={sf_local})\")\n",
        "            z = z * scale\n",
        "\n",
        "        bsz = z.shape[0] if isinstance(z, torch.Tensor) else 1\n",
        "        if isinstance(c, torch.Tensor) and c.shape[0] != bsz:\n",
        "            log(f\"[denoise] repeat cond from {c.shape[0]} -> {bsz}\")\n",
        "            c = c.repeat(bsz, 1, 1)\n",
        "\n",
        "        steps    = int(meta.get(\"steps\", DEFAULT_DDIM_STEPS))\n",
        "        eta      = float(meta.get(\"eta\", DEFAULT_DDIM_ETA))\n",
        "        strength = float(meta.get(\"strength\", DEFAULT_STRENGTH))\n",
        "        scale    = float(meta.get(\"scale\", DEFAULT_SCALE))\n",
        "        seed     = int(meta.get(\"seed\", 42))\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        sampler.make_schedule(ddim_num_steps=steps, ddim_eta=eta, verbose=False)\n",
        "        t_enc = max(0, int(round(strength * steps)))\n",
        "        t_vec = torch.tensor([t_enc]*bsz).to(device)\n",
        "\n",
        "        uc = None if scale == 1.0 else to_device(model.get_learned_conditioning([\"\"]*bsz), device)\n",
        "        amp = autocast(\"cuda\") if AMP_DEVICE==\"cuda\" else nullcontext()\n",
        "        with no_grad(), amp, model.ema_scope():\n",
        "            z_noisy = sampler.stochastic_encode(z, t_vec)\n",
        "            out = sampler.decode(z_noisy, c, t_enc,\n",
        "                                 unconditional_guidance_scale=scale,\n",
        "                                 unconditional_conditioning=uc)\n",
        "        if torch.cuda.is_available(): torch.cuda.synchronize()\n",
        "        torch.save(out.cpu(), DENOISED_FILE); os.chmod(DENOISED_FILE, 0o666)\n",
        "\n",
        "        with no_grad(): prev = model.decode_first_stage(out)\n",
        "        prev = torch.clamp((prev+1)/2, 0, 1)\n",
        "        Image.fromarray(to_uint8_img(prev[0])).save(os.path.join(OUT_DIR,\"preview_denoise.png\"))\n",
        "\n",
        "        save_flag(FLAG_DENOISE_DONE)\n",
        "        log(\"[denoise] done\")\n",
        "    except Exception:\n",
        "        log(\"[denoise] ERROR:\"); traceback.print_exc()\n",
        "\n",
        "def do_decode():\n",
        "    log(\"[decode] start\")\n",
        "    try:\n",
        "        s = torch.load(DENOISED_FILE, map_location=\"cpu\"); s = to_device(s, device)\n",
        "        with no_grad(): imgs = model.decode_first_stage(s)\n",
        "        if torch.cuda.is_available(): torch.cuda.synchronize()\n",
        "        imgs = torch.clamp((imgs+1)/2, 0, 1)\n",
        "        for img in imgs:\n",
        "            Image.fromarray(to_uint8_img(img)).save(os.path.join(OUT_DIR, f\"{time.time_ns()}.png\"))\n",
        "        log(\"[decode] done\")\n",
        "\n",
        "        for fp in [INIT_IMG, PROMPT_FILE, LATENT_FILE, COND_FILE, META_FILE, DENOISED_FILE,\n",
        "                   FLAG_ENCODE_DONE, FLAG_DENOISE_DONE, FLAG_RUN_DENOISE, FLAG_RUN_DECODE]:\n",
        "            if os.path.exists(fp):\n",
        "                try: os.remove(fp)\n",
        "                except: pass\n",
        "    except Exception:\n",
        "        log(\"[decode] ERROR:\"); traceback.print_exc()\n",
        "\n",
        "def daemon_loop():\n",
        "    log(\"[Daemon] watching…\")\n",
        "    while True:\n",
        "        try:\n",
        "            try:\n",
        "                log(f\"[ls] uploads={os.listdir(UPLOAD_DIR)} out={os.listdir(OUT_DIR)}\")\n",
        "            except: pass\n",
        "\n",
        "            if os.path.exists(INIT_IMG) and os.path.exists(PROMPT_FILE) and not os.path.exists(LATENT_FILE):\n",
        "                for old in glob.glob(os.path.join(OUT_DIR, '*.png')):\n",
        "                    if old.endswith(\"recon_encode.png\") or old.endswith(\"preview_denoise.png\"):\n",
        "                        continue\n",
        "                    try: os.remove(old)\n",
        "                    except: pass\n",
        "                do_encode()\n",
        "\n",
        "            if os.path.exists(FLAG_RUN_DENOISE) and os.path.exists(LATENT_FILE) and os.path.exists(COND_FILE):\n",
        "                try: os.remove(FLAG_RUN_DENOISE)\n",
        "                except: pass\n",
        "                do_denoise()\n",
        "\n",
        "            if os.path.exists(FLAG_RUN_DECODE) and os.path.exists(DENOISED_FILE):\n",
        "                try: os.remove(FLAG_RUN_DECODE)\n",
        "                except: pass\n",
        "                do_decode()\n",
        "\n",
        "            time.sleep(1)\n",
        "        except Exception:\n",
        "            log(\"[Daemon] loop error:\"); traceback.print_exc(); time.sleep(3)\n",
        "\n",
        "if __name__=='__main__':\n",
        "    for fp in [LATENT_FILE, COND_FILE, META_FILE, DENOISED_FILE,\n",
        "               FLAG_ENCODE_DONE, FLAG_DENOISE_DONE, FLAG_RUN_DENOISE, FLAG_RUN_DECODE]:\n",
        "        if os.path.exists(fp):\n",
        "            try: os.remove(fp)\n",
        "            except: pass\n",
        "    daemon_loop()\n"
      ],
      "metadata": {
        "id": "GhKyBwVPwRui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preload the model\n",
        "pkill -f img2img_server.py\n",
        "nohup python3 -u img2img_server.py > /var/log/img2img_server.log 2>&1 &\n",
        "tail -f /var/log/img2img_server.log"
      ],
      "metadata": {
        "id": "xgDcAJO9wTRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following code will allow the client-side model to start loading after being called, and execute the corresponding steps after model loading and receiving the flag\n",
        "nano img2img_client.py"
      ],
      "metadata": {
        "id": "ytEjLg3fwUrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "img2img_client.py\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import argparse, os, time, json, threading\n",
        "import torch, numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from einops import repeat\n",
        "from torchvision.utils import make_grid\n",
        "from torch import autocast\n",
        "from contextlib import nullcontext\n",
        "from pytorch_lightning import seed_everything\n",
        "\n",
        "from ldm.util import instantiate_from_config\n",
        "from ldm.models.diffusion.ddim import DDIMSampler\n",
        "\n",
        "def to_uint8_img(x):\n",
        "    return (x.mul(255).add_(0.5).clamp(0,255).permute(1,2,0).detach().cpu().numpy().astype(np.uint8))\n",
        "\n",
        "def _load_all(opt):\n",
        "    seed_everything(opt.seed)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    cfg = OmegaConf.load(opt.config)\n",
        "    pl_sd = torch.load(opt.ckpt, map_location=\"cpu\")\n",
        "    sd = pl_sd.get(\"state_dict\", pl_sd)\n",
        "    model = instantiate_from_config(cfg.model); model.load_state_dict(sd, strict=False)\n",
        "    model = model.to(device).eval()\n",
        "    sampler = DDIMSampler(model)\n",
        "    return model, sampler, device\n",
        "\n",
        "class AsyncLoader:\n",
        "    def __init__(self, opt):\n",
        "        self._e = threading.Event(); self._res=None\n",
        "        threading.Thread(target=self._run, args=(opt,), daemon=True).start()\n",
        "    def _run(self, opt):\n",
        "        self._res = _load_all(opt); self._e.set()\n",
        "    def get(self):\n",
        "        self._e.wait(); return self._res\n",
        "\n",
        "def _load_image(path, device, n):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    w, h = img.size; w -= w%32; h -= h%32\n",
        "    img = img.resize((w,h), resample=Image.LANCZOS)\n",
        "    arr = np.array(img).astype(np.float32)/255.0\n",
        "    x = torch.from_numpy(arr[None].transpose(0,3,1,2)).to(device)*2-1\n",
        "    return repeat(x,'1 ... -> b ...', b=n), (w,h)\n",
        "\n",
        "def _to_device(x, device):\n",
        "    if isinstance(x, torch.Tensor): return x.to(device)\n",
        "    if isinstance(x, (list,tuple)): return [ _to_device(t, device) for t in x ]\n",
        "    if isinstance(x, dict): return {k:_to_device(v, device) for k,v in x.items()}\n",
        "    return x\n",
        "\n",
        "def encode_stage(opt, loader):\n",
        "    model, sampler, device = loader.get()\n",
        "    x, (w,h) = _load_image(opt.init_img, device, opt.n_samples)\n",
        "    with torch.no_grad(): z = model.get_first_stage_encoding(model.encode_first_stage(x))\n",
        "    torch.save(z.cpu(), opt.latent_out)\n",
        "\n",
        "    with torch.no_grad(): c = model.get_learned_conditioning([opt.prompt]*opt.n_samples)\n",
        "    if isinstance(c, torch.Tensor): torch.save(c.cpu(), opt.cond_out)\n",
        "    elif isinstance(c, (list,tuple)): torch.save([t.cpu() if isinstance(t, torch.Tensor) else t for t in c], opt.cond_out)\n",
        "    elif isinstance(c, dict): torch.save({k:(v.cpu() if isinstance(v, torch.Tensor) else v) for k,v in c.items()}, opt.cond_out)\n",
        "    else: torch.save(c, opt.cond_out)\n",
        "\n",
        "    sf_local = float(getattr(model, \"scale_factor\", 0.18215))\n",
        "    meta = {\n",
        "        \"width\": w, \"height\": h, \"n_samples\": opt.n_samples,\n",
        "        \"steps\": opt.ddim_steps, \"eta\": opt.ddim_eta,\n",
        "        \"strength\": opt.strength, \"scale\": opt.scale,\n",
        "        \"scale_factor\": sf_local,\n",
        "        \"ckpt\": os.path.basename(opt.ckpt),\n",
        "        \"config\": os.path.basename(opt.config),\n",
        "        \"seed\": opt.seed\n",
        "    }\n",
        "    with open(opt.meta_out, \"w\") as f: json.dump(meta, f, indent=2)\n",
        "\n",
        "    with torch.no_grad(): recon = model.decode_first_stage(z)\n",
        "    recon = torch.clamp((recon+1)/2, 0, 1)\n",
        "    os.makedirs(opt.outdir, exist_ok=True)\n",
        "    Image.fromarray(to_uint8_img(recon[0])).save(os.path.join(opt.outdir, \"recon_encode.png\"))\n",
        "    print(f\"[encode] latent:{tuple(z.shape)} sf:{sf_local}\")\n",
        "\n",
        "def denoise_stage(opt, loader):\n",
        "    model, sampler, device = loader.get()\n",
        "    z  = torch.load(opt.latent_out, map_location=\"cpu\"); z = _to_device(z, device)\n",
        "    cc = torch.load(opt.cond_out,   map_location=\"cpu\"); c = _to_device(cc, device)\n",
        "    with open(opt.meta_out) as f: meta = json.load(f)\n",
        "\n",
        "    sf_send = float(meta.get(\"scale_factor\", float(getattr(model,\"scale_factor\",0.18215))))\n",
        "    sf_local= float(getattr(model, \"scale_factor\", 0.18215))\n",
        "    if abs(sf_send - sf_local) > 1e-6:\n",
        "        z = z * (sf_send/sf_local)\n",
        "        print(f\"[denoise] rescale latent by {(sf_send/sf_local):.6f}\")\n",
        "\n",
        "    bsz = z.shape[0] if isinstance(z, torch.Tensor) else 1\n",
        "    if isinstance(c, torch.Tensor) and c.shape[0] != bsz:\n",
        "        c = c.repeat(bsz, 1, 1)\n",
        "\n",
        "    steps    = int(meta.get(\"steps\", opt.ddim_steps))\n",
        "    eta      = float(meta.get(\"eta\", opt.ddim_eta))\n",
        "    strength = float(meta.get(\"strength\", opt.strength))\n",
        "    scale    = float(meta.get(\"scale\", opt.scale))\n",
        "    seed     = int(meta.get(\"seed\", opt.seed))\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    sampler.make_schedule(ddim_num_steps=steps, ddim_eta=eta, verbose=False)\n",
        "    t_enc = max(0, int(round(strength * steps)))\n",
        "    t_vec = torch.tensor([t_enc]*bsz).to(device)\n",
        "\n",
        "    uc = None if scale==1.0 else _to_device(model.get_learned_conditioning([\"\"]*bsz), device)\n",
        "    amp = autocast(\"cuda\") if (opt.precision==\"autocast\" and device.type==\"cuda\") else nullcontext()\n",
        "    with torch.no_grad(), amp, model.ema_scope():\n",
        "        z_noisy = sampler.stochastic_encode(z, t_vec)\n",
        "        s = sampler.decode(z_noisy, c, t_enc,\n",
        "                           unconditional_guidance_scale=scale,\n",
        "                           unconditional_conditioning=uc)\n",
        "    torch.save(s.cpu(), opt.denoised_out)\n",
        "\n",
        "    with torch.no_grad(): prev = model.decode_first_stage(s)\n",
        "    prev = torch.clamp((prev+1)/2, 0, 1)\n",
        "    Image.fromarray(to_uint8_img(prev[0])).save(os.path.join(opt.outdir, \"preview_denoise.png\"))\n",
        "    print(f\"[denoise] steps={steps} strength={strength} t_enc={t_enc}\")\n",
        "\n",
        "def decode_stage(opt, loader):\n",
        "    model, sampler, device = loader.get()\n",
        "    s = torch.load(opt.denoised_out, map_location=\"cpu\")\n",
        "    if not isinstance(s, torch.Tensor):\n",
        "        raise TypeError(\"denoised_latent.pt must be Tensor\")\n",
        "    s = s.to(device)\n",
        "    with torch.no_grad(): imgs = model.decode_first_stage(s)\n",
        "    imgs = torch.clamp((imgs+1)/2, 0, 1)\n",
        "    os.makedirs(opt.outdir, exist_ok=True)\n",
        "    Image.fromarray(to_uint8_img(imgs[0])).save(os.path.join(opt.outdir, \"final.png\"))\n",
        "    print(f\"[decode] saved {os.path.join(opt.outdir,'final.png')}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import time as _time\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--prompt\", required=True)\n",
        "    p.add_argument(\"--init-img\", required=True)\n",
        "    p.add_argument(\"--outdir\", default=\"outputs/img2img-samples\")\n",
        "    p.add_argument(\"--latent-out\",   default=\"init_latent.pt\")\n",
        "    p.add_argument(\"--cond-out\",     default=\"encoded_condition.pt\")\n",
        "    p.add_argument(\"--meta-out\",     default=\"intermediate_meta.json\")\n",
        "    p.add_argument(\"--denoised-out\", default=\"denoised_latent.pt\")\n",
        "    p.add_argument(\"--ddim_steps\",   type=int,   default=50)\n",
        "    p.add_argument(\"--ddim_eta\",     type=float, default=0.0)\n",
        "    p.add_argument(\"--n_samples\",    type=int,   default=1)\n",
        "    p.add_argument(\"--strength\",     type=float, default=0.30)\n",
        "    p.add_argument(\"--scale\",        type=float, default=5.0)\n",
        "    p.add_argument(\"--precision\",    choices=[\"full\",\"autocast\"], default=\"autocast\")\n",
        "    p.add_argument(\"--config\",       default=\"configs/stable-diffusion/v1-inference.yaml\")\n",
        "    p.add_argument(\"--ckpt\",         default=\"models/ldm/stable-diffusion-v1/model.ckpt\")\n",
        "    p.add_argument(\"--seed\",         type=int,   default=42)\n",
        "    opt = p.parse_args()\n",
        "\n",
        "    loader = AsyncLoader(opt)\n",
        "    print(\"[client_local] watching flags…\")\n",
        "    for name, func in [(\"encode\", encode_stage), (\"denoise\", denoise_stage), (\"decode\", decode_stage)]:\n",
        "        flag = f\"{name}.flag\"\n",
        "        while True:\n",
        "            if os.path.exists(flag):\n",
        "                print(f\"=== {name} ===\"); func(opt, loader); os.remove(flag); break\n",
        "            _time.sleep(0.5)\n",
        "    print(\"✅ done\")\n"
      ],
      "metadata": {
        "id": "FGR981ixwV4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After both the client and server have enabled stable diffusion through Docker, modified the above code\n",
        "# Please remember that the network configuration needs to be modified according to the actual situation.\n",
        "# By default, the CPU and MEM usage are used to determine which device to execute the task.\n",
        "# However, you can modify some code to force certain steps to be executed on a certain device for testing.\n",
        "pip install paramiko\n",
        "nano client.py"
      ],
      "metadata": {
        "id": "fe6k8D0twW6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "client.py\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import argparse, time, os, io, csv, json, subprocess, paramiko, threading, traceback\n",
        "import torch, numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from einops import repeat\n",
        "from pytorch_lightning import seed_everything\n",
        "from ldm.util import instantiate_from_config\n",
        "from ldm.models.diffusion.ddim import DDIMSampler\n",
        "from contextlib import nullcontext\n",
        "from torch import autocast\n",
        "\n",
        "CSV_DIR = \"/data/images/stable-diffusion\"\n",
        "\n",
        "# Network Configuration\n",
        "EDGE_SERVER_IP   = \"100.110.165.80\"\n",
        "EDGE_SERVER_USER = \"host\"\n",
        "EDGE_SERVER_PWD  = \"123\"\n",
        "MONITOR_SCRIPT   = \"/home/host/monitor.py\"\n",
        "\n",
        "REMOTE_BASE      = \"/data/images/stable-diffusion\"\n",
        "REMOTE_UPLOAD    = os.path.join(REMOTE_BASE, \"uploads\")\n",
        "REMOTE_OUT       = os.path.join(REMOTE_BASE, \"test\")\n",
        "\n",
        "FLAG_ENCODE_DONE  = os.path.join(REMOTE_UPLOAD, \"encode_done.flag\")\n",
        "FLAG_DENOISE_DONE = os.path.join(REMOTE_UPLOAD, \"denoise_done.flag\")\n",
        "FLAG_RUN_DENOISE  = os.path.join(REMOTE_UPLOAD, \"run_denoise.flag\")\n",
        "FLAG_RUN_DECODE   = os.path.join(REMOTE_UPLOAD, \"run_decode.flag\")\n",
        "\n",
        "LATENT_LOCAL  = \"init_latent.pt\"\n",
        "COND_LOCAL    = \"encoded_condition.pt\"\n",
        "META_LOCAL    = \"intermediate_meta.json\"\n",
        "DENOISED_LOCAL= \"denoised_latent.pt\"\n",
        "\n",
        "def log(m): print(m, flush=True)\n",
        "\n",
        "class StageTimer:\n",
        "    def __init__(self):\n",
        "        self.metrics = {k: 0.0 for k in (\"encode\",\"denoise\",\"decode\")}\n",
        "        self.cur = None; self.t0  = None\n",
        "    def _now(self): return time.perf_counter()\n",
        "    def start(self, stage: str): self.cur = stage; self.t0 = self._now()\n",
        "    def switch(self, next_stage: str):\n",
        "        now = self._now()\n",
        "        if self.cur is not None: self.metrics[self.cur] += now - self.t0\n",
        "        self.cur = next_stage; self.t0 = now\n",
        "    def stop(self):\n",
        "        now = self._now()\n",
        "        if self.cur is not None: self.metrics[self.cur] += now - self.t0\n",
        "\n",
        "def _init_local_model(cfg_path, ckpt_path, seed):\n",
        "    seed_everything(seed)\n",
        "    cfg = OmegaConf.load(cfg_path)\n",
        "    pl  = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    sd  = pl.get(\"state_dict\", pl)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model  = instantiate_from_config(cfg.model); model.load_state_dict(sd, strict=False)\n",
        "    model  = model.to(device).eval()\n",
        "    sampler= DDIMSampler(model)\n",
        "    return model, sampler, device\n",
        "\n",
        "class AsyncModelLoader:\n",
        "    def __init__(self, cfg, ckpt, seed):\n",
        "        self._e = threading.Event(); self._res=None\n",
        "        threading.Thread(target=self._load, args=(cfg,ckpt,seed), daemon=True).start()\n",
        "    def _load(self, cfg, ckpt, seed):\n",
        "        try: self._res = _init_local_model(cfg, ckpt, seed); log(\"[loader] model ready\")\n",
        "        except Exception: log(\"[loader] model failed\"); traceback.print_exc()\n",
        "        finally: self._e.set()\n",
        "    def get(self):\n",
        "        self._e.wait()\n",
        "        if self._res is None: raise RuntimeError(\"model load failed\")\n",
        "        return self._res\n",
        "\n",
        "def make_ssh():\n",
        "    ssh = paramiko.SSHClient()\n",
        "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
        "    ssh.connect(EDGE_SERVER_IP, username=EDGE_SERVER_USER, password=EDGE_SERVER_PWD)\n",
        "    return ssh\n",
        "\n",
        "def server_ok(ssh):\n",
        "    try:\n",
        "        _, stdout, _ = ssh.exec_command(f\"python3 {MONITOR_SCRIPT}\")\n",
        "        stat = json.loads(stdout.read().decode() or \"{}\")\n",
        "        cpu = stat.get(\"cpu\", 100); mem = stat.get(\"mem\", 100)\n",
        "        ok = (cpu < 80) and (mem < 80)\n",
        "        log(f\"[server_ok] cpu={cpu} mem={mem} -> {ok}\")\n",
        "        return ok\n",
        "    except Exception:\n",
        "        log(\"[server_ok] monitor failed -> False\"); traceback.print_exc(); return False\n",
        "\n",
        "def r_exists(sftp, path):\n",
        "    try: sftp.stat(path); return True\n",
        "    except Exception: return False\n",
        "\n",
        "def r_list(sftp, path):\n",
        "    try: return sftp.listdir(path)\n",
        "    except Exception: return []\n",
        "\n",
        "def wait_remote(ssh, path, poll, timeout, name):\n",
        "    t0 = time.time(); snap=0\n",
        "    while True:\n",
        "        with ssh.open_sftp() as sftp:\n",
        "            if r_exists(sftp, path): log(f\"[remote] found {name}\"); return True\n",
        "            now=time.time()\n",
        "            if now - snap >= 5:\n",
        "                log(f\"[remote] waiting {name}… uploads={r_list(sftp, REMOTE_UPLOAD)} out={r_list(sftp, REMOTE_OUT)}\")\n",
        "                snap=now\n",
        "        if time.time()-t0 > timeout: log(f\"[remote] timeout {name}\"); return False\n",
        "        time.sleep(poll)\n",
        "\n",
        "def r_put(ssh, l, r):\n",
        "    with ssh.open_sftp() as sftp:\n",
        "        try: sftp.mkdir(os.path.dirname(r))\n",
        "        except: pass\n",
        "        sftp.put(l, r)\n",
        "def r_put_flag(ssh, r):\n",
        "    with ssh.open_sftp() as sftp:\n",
        "        try: sftp.mkdir(os.path.dirname(r))\n",
        "        except: pass\n",
        "        sftp.putfo(io.BytesIO(b\"\"), r)\n",
        "def r_get(ssh, r, l):\n",
        "    with ssh.open_sftp() as sftp: sftp.get(r, l)\n",
        "\n",
        "def to_uint8_img(x):\n",
        "    return (x.mul(255).add_(0.5).clamp(0,255).permute(1,2,0).cpu().numpy().astype(np.uint8))\n",
        "\n",
        "def local_encode(args, loader):\n",
        "    log(\"[local] ENCODE\")\n",
        "    model, sampler, device = loader.get()\n",
        "    img = Image.open(args.init_img).convert(\"RGB\")\n",
        "    w,h = img.size; w-=w%32; h-=h%32\n",
        "    img = img.resize((w,h), resample=Image.LANCZOS)\n",
        "    arr = np.array(img, dtype=np.float32)/255.0\n",
        "    x = torch.from_numpy(arr.transpose(2,0,1)).unsqueeze(0).to(device)*2-1\n",
        "    with torch.no_grad(): z = model.get_first_stage_encoding(model.encode_first_stage(x))\n",
        "    torch.save(z.cpu(), LATENT_LOCAL)\n",
        "\n",
        "    with torch.no_grad(): c = model.get_learned_conditioning([args.prompt])\n",
        "    if isinstance(c, torch.Tensor): torch.save(c.cpu(), COND_LOCAL)\n",
        "    elif isinstance(c, (list,tuple)): torch.save([t.cpu() if isinstance(t, torch.Tensor) else t for t in c], COND_LOCAL)\n",
        "    elif isinstance(c, dict): torch.save({k:(v.cpu() if isinstance(v, torch.Tensor) else v) for k,v in c.items()}, COND_LOCAL)\n",
        "    else: torch.save(c, COND_LOCAL)\n",
        "\n",
        "    sf_local = float(getattr(model,\"scale_factor\",0.18215))\n",
        "    meta = {\n",
        "        \"width\": w, \"height\": h, \"n_samples\": 1,\n",
        "        \"steps\": args.ddim_steps, \"eta\": args.ddim_eta,\n",
        "        \"strength\": args.strength, \"scale\": args.scale,\n",
        "        \"scale_factor\": sf_local, \"ckpt\": os.path.basename(args.ckpt),\n",
        "        \"config\": os.path.basename(args.config), \"seed\": args.seed\n",
        "    }\n",
        "    with open(META_LOCAL,\"w\") as f: json.dump(meta, f, indent=2)\n",
        "\n",
        "    with torch.no_grad(): recon = model.decode_first_stage(z)\n",
        "    Image.fromarray(to_uint8_img(torch.clamp((recon+1)/2,0,1)[0])).save(\"recon_encode.png\")\n",
        "\n",
        "def local_denoise(args, loader):\n",
        "    log(\"[local] DENOISE\")\n",
        "    model, sampler, device = loader.get()\n",
        "    z = torch.load(LATENT_LOCAL, map_location=\"cpu\").to(device)\n",
        "    with open(META_LOCAL) as f: meta = json.load(f)\n",
        "    sf_send  = float(meta.get(\"scale_factor\", float(getattr(model,\"scale_factor\",0.18215))))\n",
        "    sf_local = float(getattr(model,\"scale_factor\",0.18215))\n",
        "    if abs(sf_send-sf_local)>1e-6:\n",
        "        z = z * (sf_send/sf_local); log(f\"[local] rescale latent {(sf_send/sf_local):.6f}\")\n",
        "\n",
        "    steps    = int(meta.get(\"steps\", args.ddim_steps))\n",
        "    eta      = float(meta.get(\"eta\", args.ddim_eta))\n",
        "    strength = float(meta.get(\"strength\", args.strength))\n",
        "    scale    = float(meta.get(\"scale\", args.scale))\n",
        "    seed     = int(meta.get(\"seed\", args.seed))\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    sampler.make_schedule(ddim_num_steps=steps, ddim_eta=eta, verbose=False)\n",
        "    t_enc = max(0, int(round(strength*steps)))\n",
        "    uc = None if scale==1.0 else model.get_learned_conditioning([\"\"])\n",
        "    uc = uc.to(device) if isinstance(uc, torch.Tensor) else uc\n",
        "    c  = torch.load(COND_LOCAL, map_location=\"cpu\")\n",
        "    if isinstance(c, torch.Tensor): c = c.to(device)\n",
        "    t_vec = torch.tensor([t_enc]).to(device)\n",
        "    amp = autocast(\"cuda\") if torch.cuda.is_available() else nullcontext()\n",
        "    with torch.no_grad(), amp, model.ema_scope():\n",
        "        z_noisy = sampler.stochastic_encode(z, t_vec)\n",
        "        s = sampler.decode(z_noisy, c, t_enc,\n",
        "                           unconditional_guidance_scale=scale,\n",
        "                           unconditional_conditioning=uc)\n",
        "    torch.save(s.cpu(), DENOISED_LOCAL)\n",
        "    with torch.no_grad(): prev = model.decode_first_stage(s)\n",
        "    Image.fromarray(to_uint8_img(torch.clamp((prev+1)/2,0,1)[0])).save(\"preview_denoise.png\")\n",
        "\n",
        "def local_decode(args, loader):\n",
        "    log(\"[local] DECODE\")\n",
        "    model, sampler, device = loader.get()\n",
        "    s = torch.load(DENOISED_LOCAL, map_location=\"cpu\").to(device)\n",
        "    with torch.no_grad(): imgs = model.decode_first_stage(s)\n",
        "    imgs = torch.clamp((imgs+1)/2, 0, 1)\n",
        "    Image.fromarray(to_uint8_img(imgs[0])).save(args.output)\n",
        "    log(f\"[local] saved {args.output}\")\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--prompt\", required=True)\n",
        "    ap.add_argument(\"--init-img\", required=True)\n",
        "    ap.add_argument(\"--output\", required=True)\n",
        "    ap.add_argument(\"--seed\", type=int, default=42)\n",
        "    ap.add_argument(\"--strength\", type=float, default=0.30)\n",
        "    ap.add_argument(\"--ddim_steps\", type=int, default=50)\n",
        "    ap.add_argument(\"--ddim_eta\", type=float, default=0.0)\n",
        "    ap.add_argument(\"--scale\", type=float, default=5.0)\n",
        "    ap.add_argument(\"--config\", default=\"/opt/stable-diffusion/configs/stable-diffusion/v1-inference.yaml\")\n",
        "    ap.add_argument(\"--ckpt\",   default=\"/data/models/stable-diffusion/sd-v1-5.ckpt\")\n",
        "    ap.add_argument(\"--poll-interval\", type=float, default=1.0)\n",
        "    ap.add_argument(\"--remote_timeout\", type=float, default=120.0)\n",
        "    ap.add_argument(\"--mode\", choices=[\"auto\",\"local\",\"server\"], default=\"auto\")\n",
        "    ap.add_argument(\"--no-fallback\", action=\"store_true\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    loader = AsyncModelLoader(args.config, args.ckpt, args.seed)\n",
        "    ssh = make_ssh()\n",
        "\n",
        "    def want_server(stage):\n",
        "        if args.mode==\"server\": return True\n",
        "        if args.mode==\"local\":  return False\n",
        "        return server_ok(ssh)\n",
        "\n",
        "    timer = StageTimer()\n",
        "    timer.start(\"encode\")\n",
        "\n",
        "    if want_server(\"ENCODE\"):\n",
        "        log(\"[branch] ENCODE on SERVER\")\n",
        "        subprocess.run(f\"cp {args.init_img} init_img.png\", shell=True, check=True)\n",
        "        with open(\"prompt.txt\",\"w\") as f: f.write(args.prompt)\n",
        "        with ssh.open_sftp() as sftp:\n",
        "            try: sftp.mkdir(REMOTE_UPLOAD)\n",
        "            except: pass\n",
        "\n",
        "        with ssh.open_sftp() as sftp:\n",
        "            sftp.put(\"init_img.png\", os.path.join(REMOTE_UPLOAD, \"init_img.png\"))\n",
        "            sftp.put(\"prompt.txt\",   os.path.join(REMOTE_UPLOAD, \"prompt.txt\"))\n",
        "        ok = wait_remote(ssh, FLAG_ENCODE_DONE, args.poll_interval, args.remote_timeout, \"encode_done.flag\")\n",
        "        if not ok:\n",
        "            if args.no_fallback: raise TimeoutError(\"ENCODE remote timeout\")\n",
        "            log(\"[fallback] ENCODE -> LOCAL\")\n",
        "            local_encode(args, loader)\n",
        "    else:\n",
        "        log(\"[branch] ENCODE on LOCAL\")\n",
        "        local_encode(args, loader)\n",
        "\n",
        "    if torch.cuda.is_available(): torch.cuda.synchronize()\n",
        "    timer.switch(\"denoise\")\n",
        "\n",
        "    if want_server(\"DENOISE\"):\n",
        "        log(\"[branch] DENOISE on SERVER\")\n",
        "\n",
        "        with ssh.open_sftp() as sftp:\n",
        "            has_server_latent = os.path.basename(LATENT_LOCAL) in sftp.listdir(REMOTE_UPLOAD)\n",
        "        if not has_server_latent and os.path.exists(LATENT_LOCAL):\n",
        "            r_put(ssh, LATENT_LOCAL, os.path.join(REMOTE_UPLOAD, \"init_latent.pt\"))\n",
        "            r_put(ssh, COND_LOCAL,   os.path.join(REMOTE_UPLOAD, \"encoded_condition.pt\"))\n",
        "            r_put(ssh, META_LOCAL,   os.path.join(REMOTE_UPLOAD, \"intermediate_meta.json\"))\n",
        "        r_put_flag(ssh, FLAG_RUN_DENOISE)\n",
        "        ok = wait_remote(ssh, FLAG_DENOISE_DONE, args.poll_interval, args.remote_timeout, \"denoise_done.flag\")\n",
        "        if not ok:\n",
        "            if args.no_fallback: raise TimeoutError(\"DENOISE remote timeout\")\n",
        "            log(\"[fallback] DENOISE -> LOCAL\")\n",
        "            local_denoise(args, loader)\n",
        "    else:\n",
        "        log(\"[branch] DENOISE on LOCAL\")\n",
        "        local_denoise(args, loader)\n",
        "\n",
        "    if torch.cuda.is_available(): torch.cuda.synchronize()\n",
        "    timer.switch(\"decode\")\n",
        "\n",
        "    if want_server(\"DECODE\"):\n",
        "        log(\"[branch] DECODE on SERVER\")\n",
        "        r_put_flag(ssh, FLAG_RUN_DECODE)\n",
        "        t0=time.time(); name=None\n",
        "        while True:\n",
        "            with ssh.open_sftp() as sftp:\n",
        "                outs = sftp.listdir(REMOTE_OUT)\n",
        "                pngs = sorted([f for f in outs if f.endswith(\".png\") and f not in (\"recon_encode.png\",\"preview_denoise.png\")])\n",
        "                log(f\"[remote] out={outs}\")\n",
        "            if pngs: name=pngs[-1]; break\n",
        "            if time.time()-t0>args.remote_timeout:\n",
        "                if args.no_fallback: raise TimeoutError(\"DECODE remote timeout\")\n",
        "                log(\"[fallback] DECODE -> LOCAL\"); break\n",
        "            time.sleep(args.poll_interval)\n",
        "        if name:\n",
        "            r_get(ssh, os.path.join(REMOTE_OUT, name), args.output)\n",
        "        else:\n",
        "            local_decode(args, loader)\n",
        "    else:\n",
        "        log(\"[branch] DECODE on LOCAL\")\n",
        "        local_decode(args, loader)\n",
        "\n",
        "    if torch.cuda.is_available(): torch.cuda.synchronize()\n",
        "    timer.stop()\n",
        "\n",
        "    os.makedirs(CSV_DIR, exist_ok=True)\n",
        "    existing = [f for f in os.listdir(CSV_DIR) if f.endswith(\".csv\") and f[:-4].isdigit()]\n",
        "    next_idx = (max(map(int,[f[:-4] for f in existing]))+1) if existing else 0\n",
        "    with open(os.path.join(CSV_DIR,f\"{next_idx}.csv\"),\"w\",newline=\"\") as f:\n",
        "        w=csv.writer(f); w.writerow([\"stage\",\"delay\"])\n",
        "        w.writerow([\"encode\",f\"{timer.metrics['encode']:.6f}\"])\n",
        "        w.writerow([\"denoise\",f\"{timer.metrics['denoise']:.6f}\"])\n",
        "        w.writerow([\"decode\",f\"{timer.metrics['decode']:.6f}\"])\n",
        "    log(\"[+] latency csv written\")\n",
        "    ssh.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "clXS4jrVwY0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python3 client.py \\\n",
        "  --prompt \"high quality, sharp focus, crisp street details, natural lighting, balanced contrast, accurate colors, clean edges, realistic textures, photorealistic\" \\\n",
        "  --init-img /data/images/stable-diffusion/samples/input.png \\\n",
        "  --output /data/images/stable-diffusion/test/output.png \\\n",
        "  --n_samples 1 --seed $(python3 -c 'import secrets; print(1 + secrets.randbelow(2147483646))') --strength 0.3 --ddim_steps 50\n"
      ],
      "metadata": {
        "id": "qkZg8OYkO8Ok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}